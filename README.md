# SPMalloc

SPMalloc is a scalable library to intercept function calls of *malloc, calloc, realloc, free* in C and *new,delete* in C++
to place allocation objects on heterogeneous memory systems. It replaces the original functions of glibc with custom ones by using
the respective functions of the MEMKIND API. 
The library is compiled into a shared object (.so file) and then preloaded to the target executable using LD_PRELOAD.
The library is further extended to perform monitoring of the allocation patterns of the
target executable, by monitoring the size and the number of active allocated objects. Optane is used in our case, but you can adapt the functionality
to your own memory type supported by the Memkind API.

We also present our **spike-based algorithm for data placement**, implemented in Python.  
This algorithm utilizes data generated by **SPMalloc's monitoring tool** together with the **Intel PCM monitoring tool**.  
It analyzes both bandwidth and allocation-level information to produce an `output.txt` file, which guides data placement decisions between **DRAM** and **Optane** for the corresponding benchmark.  
The resulting `output.txt` file is then fed back to the **SPMalloc** library, which applies the optimized placement strategy during execution.



## Table of Contents
- [Library File Descriptions](#Library-File-Descriptions)
- [Installation](#installation)
- [Usage](#usage)
- [Spike Analysis Algorithm](#Spike-Analysis-Algorithm)
- [Notes](#Notes)
- [Contributing](#contributing)
- [License](#license)

## Library File Descriptions 
In this repo, you will find a number of files, each one with its own functionality for data placement on heterogeneous memory systems.

File descriptions:
- **custom_allocator.c** : This file is used to perform allocations either on DRAM or Optane exclusively. It includes the custom functions that are used to override the original
  glibc implementations. If the *dram* variable is set to 1, all allocations will be handled by DRAM, and if *dram=0* all allocations will be handled by optane.

- **monitor.c** : This file is used to perform allocations on DRAM and also monitor the allocation patterns during the execution of the
  target application. A background thread is used, which logs information about the allocated bytes and active allocated objects over time.

- **placement.c** : This file handles data placement between DRAM and Optane based on the profiling and placement decisions generated by our algorithm. It reads the output.txt file produced by the placement algorithm and sequentially allocates memory according to the values in the file. The allocation alternates between the two memory types, starting with Optane. Each line in output.txt specifies the number of bytes to allocate to the current memory type before switching to the other.

For example, if output.txt contains:
  > 1000  
  > 2000  
  > 3000
  
  this means that the algorithm must place the first 1 kB to optane, the next 2 kB after that to Dram,
  and the next 3 kB to Optane. This process continues until all entries in the file are processed, ensuring that memory is allocated according to the algorithm's placement strategy.

- **functions.cpp** : This file includes the new/delete functions from C++, which are simply redirected to the custom functions of the .c file (e.g. custom_allocator.c).


## Installation
Clone the repository:
```bash
git clone https://github.com/ArisGr/SPMalloc
```
Change directory:
```bash
cd spmalloc
```

Then compile the desired file using the necessary flags, like this (example for custom_allocator.c):

```bash
g++ -shared -fPIC -o spmalloc.so custom_allocator.c functions.cpp -lmemkind
```

this command compiles the custom_allocator.c file, which includes the custom implementation for the C allocation and deallocation functions, and the functions.cpp 
file, which includes the respective C++ functions, into a shared object called spmalloc.so.

The flags used:
- **shared**:  This tells the compiler to create a shared library (also called a dynamic library).
- **fPIC**:  It generates code that can be loaded at any memory address without requiring modification.
- **lmemkind**:  Links against the memkind library (necessary for the memkind funcions).



## Usage
Run the target executable (e.g test) using LD_PRELOAD with the shared library:
```bash
LD_PRELOAD=/path/to/library/spmalloc.so /path/to/executable/test
```
If the library used was the one compiled from the the monitor.c file, which performs monitoring, a log file is produced.
This file displays the allocated bytes and active allocated objects over time 
for the execution of the target application.

Here's how the log file looks :

<img width="598" height="455" alt="Image" src="https://github.com/user-attachments/assets/7f3908a5-8a73-496a-8706-875b244962db" />

The active objects value is the number of active allocation objects from the beginning of the execution until the current time stamp, and
the allocated bytes value is the number of allocated bytes in the current x second time stamp. In the example above x=0.25s, but this value is user defined and can be changed to fit the users preference.



## Spike Analysis Algorithm

In this repo, you will also find our novel, spike-based algorithm designed for efficient data analysis and placement on heterogeneous memory systems. It is broken into a number of files which can be described as such:

- **main.py** : The main orchestrator of the spike analysis tool. It calls functions from all other modules to perform the full workflow: argument parsing, data extraction, spike detection, top-k spike selection, allocated bytes calculation, and output.

- **parse_args.py** : Handles command-line argument parsing and file path setup. This module allows you to specify benchmark name, `k` parameter for the k-max selection, and the window size parameter for the bw spike detector.

- **extract_info.py** : Reads and extracts relevant data from CSV and TXT files. It extracts the following information:
  - CSV ‚Üí Optane and DRAM writes
  - TXT ‚Üí allocated bytes and active objects over time

- **detectors.py** : Detect spikes in memory activity.
  - `ao_spike_detector` ‚Üí detects active-object spikes
  - `bw_spike_detector` ‚Üí detects bandwidth spikes

- **top_k_spike_selector.py** : Selects the top-k significant spikes using an interval-tree-based algorithm.

- **alculate_allocated_bytes_of_intervals.py** : Contains the `calculate_allocated_bytes` function, which computes the allocated bytes corresponding to each selected spike.

- **save_to_file.py** : Saves the resulting allocated bytes summary to a file (`output.txt`), which will later be used by the placement.c handler to make placement decisions.

## Notes

- Our algorithm is designed to handle `pcm-memory.csv` files generated by the Intel PCM monitoring program. Users should provide these files for analysis.

- For bandwidth (BW) information, the program expects:
  - `benchmark_name_dram-pcm-memory.csv` ‚Üí for DRAM
  - `benchmark_name_optane-pcm-memory.csv` ‚Üí for Optane  
  Users can either rename their files to match this format or modify the `parse_args.py` module to handle different naming conventions.

- For active objects and allocated bytes, the algorithm uses the `logfile.txt` produced by the `monitor.c` file when preloaded with the benchmark.  
  The expected format is: `benchmark_name_logfile.txt`  
  Again, users can either provide files in this format or adjust `parse_args.py` to match different descriptions.

- To run the algorithm, use the following command:
  ```bash
  python main.py -i benchmark_name -k k-param -s window_size
  ```

  Example with the provided sample benchmark:
  ```bash
  python main.py -i example -k 1 -s 10
  ```
  After execution, the algorithm generates output.txt, which contains the placement decisions.
  This file is then used by placement.c when preloaded with the benchmark to optimize data placement between DRAM and Optane memory.

## Features
- üöÄ Fast and efficient
- üõ†Ô∏è Easy to use
- ‚öôÔ∏è Customizable and scalable

## Contributing
Contributions are welcome! Feel free to expand and experiment with this library.

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Useful Sites
- Memkind API: https://pmem.io/memkind/manpages/memkind.3/

